{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Designing and Training Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this homework, we will use the Boston Housing Dataset, that we split in three: training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reference, let's see what MSE we get using a dummy regressor. To get your point for this homework, you should do better than this reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.06726556313036"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyRegressor().fit(X_train,y_train)\n",
    "mean_squared_error(dummy.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will make our life much simpler to wrap the dataset as a torch one because it was allow us to create a dataloader which will take care of batching. On top of this, it is super easy to do. Make sure to read this carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = torch.tensor(X,dtype=torch.float)\n",
    "        self.y = torch.tensor(y,dtype=torch.float)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go, now that we have a proper torch dataset, we can create a data loader for the training set. If the dataset was truly large, we should also create dataloaders for the validation and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: design a neural network model. Your model should have at two hidden layers. You are free to choose the non-linearities. You might consider using dropout layers, and the Sequential container to simplify your model specification. If you want to try other types of layers, go for it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(Model, self).__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            nn.Linear(13,size),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(size,size),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(size,1),\n",
    "          )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**: Implement an algorithm to train your model. A few hints:<br>\n",
    "<ul>\n",
    "<li> This function will likely be over 30 lines of code, so plan ahead.\n",
    "<li> First, you should create an optimizer. You can pick whichever you want. One of the most popular one is the Adam optimizer, but there are many others: https://pytorch.org/docs/stable/optim.html\n",
    "<li> If you decide to use wandb, you should remember to initialize it before the iterations starts.\n",
    "<li> Think ahead about how you are going to keep track of the train and validation loss!\n",
    "<li> The rest of the code is one big loop that will iterate epochs times \n",
    "<li> The body of the loop has two main tasks:\n",
    "<ul>\n",
    "    <li> First, the actual training. This is where you should use your dataloader to do the training by batches. That means you will have a loop that does the usual training procedure. \n",
    "    <li> Second, you should compute the validation loss. For simplicity, you can do it using sklearn.\n",
    "    <li> Finally, make sure to keep track of the current model if it turns out to work well on the validation set!  \n",
    "</ul>\n",
    "<li> It is very likely that training the model will take a while. Not only because you will need to figure out what are the right parameters (e.g. learning rate of your optimizer, rate of dropout, size of the hidden layers), but also because errors in your code may go unnoticed. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    val_dataset = Dataset(X_val,y_val)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    best_score = None\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        running_loss = 0.\n",
    "        \n",
    "        for batch_x_train, batch_y_train in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_x_train)\n",
    "            #print(y_pred.reshape(-1).shape)\n",
    "            #print(batch_y_train.reshape(-1,1).shape)\n",
    "            mse = ((y_pred.reshape(-1) - batch_y_train)**2).sum()\n",
    "            running_loss += mse.item()\n",
    "            mse.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        running_loss /= len(train_dataset)\n",
    "        \n",
    "        # EVAL\n",
    "        model.eval()\n",
    "        val_score = 0.\n",
    "        \n",
    "        for batch_x_val, batch_y_val in val_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_x_val)\n",
    "            mse = ((y_pred.reshape(-1) - batch_y_val)**2).sum()\n",
    "            val_score += mse.item()\n",
    "            mse.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        val_score /= len(val_dataset)\n",
    "        \n",
    "        if not best_score:\n",
    "            best_score = val_score\n",
    "            torch.save(model, 'best-model.pt') \n",
    "        if val_score < best_score:\n",
    "            best_score = val_score\n",
    "            torch.save(model, 'best-model.pt')\n",
    "        \n",
    "    print(\"Train loss: \", running_loss, \"Validation loss: \", val_score, \"Best Validation loss: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade36b6b15664c9db906dde715975983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  74.46068863129952 Validation loss:  83.43913060238486 Best Validation loss:  82.78660310444079\n"
     ]
    }
   ],
   "source": [
    "train(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**: Write a function that evaluates your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # TEST\n",
    "    test_dataset = Dataset(X_test,y_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    model.eval()\n",
    "    test_score = 0.\n",
    "\n",
    "    for batch_x_test, batch_y_test in test_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x_test)\n",
    "        mse = ((y_pred.reshape(-1) - batch_y_test)**2).sum()\n",
    "        test_score += mse.item()\n",
    "        mse.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_score /= len(test_dataset)\n",
    "    return test_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.61863888718012"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
